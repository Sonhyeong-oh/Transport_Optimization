import numpy as np
import torch
import matplotlib.pyplot as plt
import networkx as nx
from sklearn_extra.cluster import KMedoids
from sklearn.metrics import silhouette_score
import matplotlib.patches as mpatches
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

'''
*** ìš©ì–´ ì„¤ëª… ***

ì”ì—¬ ë¬¼ëŸ‰ = í•´ë‹¹ êµ°ì§‘ìœ¼ë¡œ ë°°ì†¡ ì§„í–‰ ì‹œ ì´ˆê³¼ëœ or ë¶€ì¡±í•œ ë¬¼ëŸ‰
ë¶ˆê· í˜• ì ìˆ˜ = ì”ì—¬ ë¬¼ëŸ‰ì˜ ë¬¼í’ˆ ë³„(ì—´ ë³„) ì ˆëŒ“ê°’ì„ ëª¨ë‘ ë”í•œ ê°’

ex) êµ°ì§‘ ê²½ë¡œë¡œ ëª¨ë‘ ë°°ì†¡í•œ í›„ì˜ ì‚¬ê³¼, ë°°, ë°”ë‚˜ë‚˜ = [2, -1, 0] : ì”ì—¬ ë¬¼ëŸ‰
ì‚¬ê³¼ëŠ” 2ë§Œí¼ ë‚¨ìŒ(ê³µê¸‰ ê³¼ì‰), ë°°ëŠ” 1ê°œ ë¶€ì¡±í•¨(ê³µê¸‰ ë¶€ì¡±), ë°”ë‚˜ë‚˜ëŠ” ìˆ˜ìš”ì™€ ê³µê¸‰ì´ ì¼ì¹˜í–ˆìŒ
ë¶ˆê· í˜• ì ìˆ˜ = |2| + |-1| + |0| = 3

ë°©ë¬¸ ê²½ë¡œ = ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°°ì†¡ ì§„í–‰
'''

# ---------------------------------------------------------------------------------------------------------------
# ------------------------------------------ í´ëŸ¬ìŠ¤í„°ë§ì— í•„ìš”í•œ í•¨ìˆ˜ ì„ ì–¸ ------------------------------------------
# ---------------------------------------------------------------------------------------------------------------

import numpy as np
import random
from collections import defaultdict

# K-medoids ì•Œê³ ë¦¬ì¦˜ì—ì„œ ê±°ë¦¬ ì œí•œì´ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •
def constrained_k_medoids(dist_matrix, n_clusters, max_iter=10000, threshold=100, random_state=0):
    np.random.seed(random_state)
    n_samples = dist_matrix.shape[0]

    # 1. ì´ˆê¸° medoid ì„ íƒ
    medoids = np.random.choice(n_samples, size=n_clusters, replace=False).tolist()

    for iteration in range(max_iter):
        clusters = defaultdict(list)

        # 2. ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•œ í• ë‹¹
        for i in range(n_samples):
            min_dist = float('inf')
            best_medoid = None
            for m in medoids:
                if dist_matrix[i][m] < threshold:  # ì œì•½ ì¡°ê±´ í™•ì¸
                    if dist_matrix[i][m] < min_dist:
                        min_dist = dist_matrix[i][m]
                        best_medoid = m
            if best_medoid is not None:
                clusters[best_medoid].append(i)

        # ì œì•½ ìœ„ë°˜ í™•ì¸: í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ìŒì˜ ê±°ë¦¬ê°€ threshold ë¯¸ë§Œì¸ì§€
        def is_valid_cluster(members):
            for i in range(len(members)):
                for j in range(i+1, len(members)):
                    if dist_matrix[members[i]][members[j]] >= threshold:
                        return False
            return True

        # ìœ íš¨í•œ í´ëŸ¬ìŠ¤í„°ë§Œ ìœ ì§€
        clusters = {m: v for m, v in clusters.items() if is_valid_cluster(v)}

        # 3. ìƒˆë¡œìš´ Medoid ì„ íƒ
        new_medoids = []
        for cluster in clusters.values():
            min_total_dist = float('inf')
            best_candidate = None
            for i in cluster:
                total_dist = sum(dist_matrix[i][j] for j in cluster)
                if total_dist < min_total_dist:
                    min_total_dist = total_dist
                    best_candidate = i
            new_medoids.append(best_candidate)

        # 4. ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        if set(new_medoids) == set(medoids):
            break
        medoids = new_medoids

    # ìµœì¢… ë¼ë²¨ë§
    labels = [-1] * n_samples
    for label, m in enumerate(medoids):
        for i in clusters.get(m, []):
            labels[i] = label

    return {
        'medoids': medoids,
        'labels': labels,
        'clusters': clusters,
    }


# === ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚° ===
def supply_demand_imbalance_score(fixed_net_demand, labels):
    total_imbalance = 0
    for cid in np.unique(labels):
        nodes = np.where(labels == cid)[0]
        subtotal = fixed_net_demand[nodes].sum(axis=0)
        imbalance = np.abs(subtotal).sum()
        total_imbalance += imbalance
    return total_imbalance


# === í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ í¸ë„ ê²½ë¡œ ê³„ì‚° ë° ë°˜í™˜ ===
def intra_cluster_greedy_path(cluster_nodes, dist_matrix):
    if len(cluster_nodes) <= 1:
        return cluster_nodes, 0.0
    unvisited = set(cluster_nodes)
    current = unvisited.pop()
    path = [current]
    total = 0.0
    while unvisited:
        next_node = min(unvisited, key=lambda x: dist_matrix[current][x])
        total += dist_matrix[current][next_node]
        path.append(next_node)
        current = next_node
        unvisited.remove(current)
    return path, total


# === í´ëŸ¬ìŠ¤í„° í‰ê°€ ===
def evaluate_clustering(fixed_net_demand, dist_matrix, n_clusters=4, trials=10, threshold=100):
    best_results = []

    for seed in range(trials):
        result = constrained_k_medoids(
            dist_matrix=dist_matrix,
            n_clusters=n_clusters,
            threshold=threshold,
            random_state=seed
        )

        labels = result['labels']

        # -1 (í• ë‹¹ë˜ì§€ ì•Šì€ ë…¸ë“œ)ê°€ í¬í•¨ëœ ê²½ìš° silhouette ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬
        if len(set(labels)) <= 1 or -1 in labels:
            sil_score = -1
        else:
            try:
                sil_score = silhouette_score(dist_matrix, labels, metric='precomputed')
            except:
                sil_score = -1

        imbalance_score = supply_demand_imbalance_score(fixed_net_demand, labels)

        best_results.append({
            'seed': seed,
            'labels': labels,
            'silhouette': sil_score,
            'imbalance': imbalance_score,
            'medoids': result['medoids'],
            'unassigned': labels.count(-1)  # í• ë‹¹ë˜ì§€ ì•Šì€ ë…¸ë“œ ìˆ˜
        })

    sorted_results = sorted(best_results, key=lambda x: (-x['silhouette'], x['imbalance'], x['unassigned']))
    return sorted_results

# === ëª©ì í•¨ìˆ˜ ê³„ì‚° í•¨ìˆ˜ ===
def calculate_objective(
    fixed_net_demand, labels, dist_matrix,
    lambda_dist=1.0,
    penalty_singleton=5000,
    penalty_unconnected=50000
):
    total_imbalance = 0
    total_distance = 0
    penalty = 0

    for cid in np.unique(labels):
        nodes = np.where(labels == cid)[0].tolist()
        if len(nodes) <= 2:
            penalty += penalty_singleton
            continue

        subtotal = fixed_net_demand[nodes].sum(axis=0)
        imbalance = np.abs(subtotal).sum()
        total_imbalance += imbalance

        path, tour_length = intra_cluster_greedy_path(nodes, dist_matrix)
        total_distance += tour_length

        # âš ï¸ ê²½ë¡œ ì¤‘ ì—°ê²° ì•ˆ ëœ ë…¸ë“œê°€ ìˆë‹¤ë©´ íŒ¨ë„í‹° ë¶€ì—¬
        for i in range(len(path) - 1):
            if np.isinf(dist_matrix[path[i]][path[i+1]]):
                penalty += penalty_unconnected
                break

    return total_imbalance + lambda_dist * total_distance + penalty

# === ë…¸ë“œë¥¼ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ ì˜®ê¸°ëŠ” ì•Œê³ ë¦¬ì¦˜ ===
# simulate_annealing ì•Œê³ ë¦¬ì¦˜ì—ì„œ êµ°ì§‘ì„ ìµœì í™”í•  ë•Œ ì‚¬ìš©
def generate_neighbor(labels, n_clusters):
    new_labels = labels.copy()
    idx = np.random.randint(0, len(labels))
    current_cluster = labels[idx]
    new_cluster = random.choice([c for c in range(n_clusters) if c != current_cluster])
    new_labels[idx] = new_cluster
    return new_labels


# === ë‹´ê¸ˆì§ˆ ê¸°ë²• (ì „ì—­ ìµœì í™” ë¬¸ì œì— ëŒ€í•œ ì¼ë°˜ì ì¸ í™•ë¥ ì  ë©”íƒ€ ì•Œê³ ë¦¬ì¦˜) ===
# K-Medoidsë¡œ ìƒì„±ëœ êµ°ì§‘ì„ ìˆ˜ìš”ì™€ ê±°ë¦¬ë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ìµœì í™” í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
'''
temp = ë¬´ì‘ìœ„ì„± ì •ë„ (ë†’ì„ìˆ˜ë¡ ë‚˜ìœ ê²°ê³¼ë„ ìˆ˜ìš©, ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ê²°ê³¼ë§Œ ìˆ˜ìš©)
cooling = ëƒ‰ê°ë¥  (tempë¥¼ ì¡°ì •)
ì´ˆë°˜ tempë¥¼ 10ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë¬´ì‘ìœ„ íƒìƒ‰ì„ ì§„í–‰í•˜ë„ë¡í•˜ê³ , ê·¸ í›„ ëƒ‰ê°ë¥ ì„ ê³±í•´ ì¢‹ì€ ê²°ê³¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ í•¨í•¨
'''
def simulated_annealing(fixed_net_demand, init_labels, dist_matrix, lambda_dist=1.0,
                        n_clusters=4, max_iter=1000, init_temp=10.0, cooling=0.995):
    current_labels = init_labels.copy()
    current_score = calculate_objective(fixed_net_demand, current_labels, dist_matrix, lambda_dist)
    best_labels = current_labels.copy()
    best_score = current_score
    temp = init_temp

    for step in range(max_iter):
        neighbor = generate_neighbor(current_labels, n_clusters)
        neighbor_score = calculate_objective(fixed_net_demand, neighbor, dist_matrix, lambda_dist)
        delta = neighbor_score - current_score

        if delta < 0 or np.random.rand() < np.exp(-delta / temp):
            current_labels = neighbor
            current_score = neighbor_score
            if current_score < best_score:
                best_labels = current_labels.copy()
                best_score = current_score

        # í•™ìŠµ íšŸìˆ˜ê°€ ë§ì•„ì§ˆ ë•Œ tempê°€ ê³¼ë„í•˜ê²Œ ë‚®ì•„ì§€ëŠ” ê²ƒì„ ë°©ì§€
        temp = max(temp * cooling, 1e-6)

    return best_labels, best_score

# -----------------------------------------------------------------------------------------------------------------------
# ------------------------------------------ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”, ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜ ì„ ì–¸ ------------------------------------------
# -----------------------------------------------------------------------------------------------------------------------

# === ê° í´ëŸ¬ìŠ¤í„° ë³„ ê²½ë¡œ ì¶œë ¥ í•¨ìˆ˜ ===
def print_cluster_details_and_paths(fixed_net_demand, labels, dist_matrix, G, pos):
    print(f"\nâœ… ìˆ˜ê¸‰ ë¶ˆê· í˜• ì ìˆ˜(ì „ì²´): {supply_demand_imbalance_score(fixed_net_demand, labels):.2f}")
    for cluster_id in np.unique(labels):
        members = np.where(labels == cluster_id)[0].tolist()

        # 0ì´ í´ëŸ¬ìŠ¤í„°ì— ìˆìœ¼ë©´ í¬í•¨, ì•„ë‹ˆë©´ ì œì™¸
        if 0 in members:
            path_nodes = members.copy()
        else:
            path_nodes = [n for n in members if n != 0]

        subtotal = fixed_net_demand[members].sum(axis=0)
        imbalance = np.abs(subtotal).sum()
        path, tour_length = intra_cluster_greedy_path(path_nodes, dist_matrix)

        print(f"\ní´ëŸ¬ìŠ¤í„° {cluster_id}: {members}")
        print(f"  ğŸ”¹ ì”ì—¬ ë¬¼ëŸ‰ ë²¡í„°: {subtotal.tolist()} â†’ ë¶ˆê· í˜• ì ìˆ˜: {imbalance}")
        print(f"  ğŸ”¹ í¸ë„ ì´ë™ ê±°ë¦¬: {tour_length:.2f}")
        print(f"  ğŸ”¹ ë°©ë¬¸ ê²½ë¡œ: {path}")
        visualize_path_on_graph(G, pos, labels, path, cluster_id, tour_length, fixed_net_demand)


# === êµ°ì§‘ ê·¸ë˜í”„ + ê²½ë¡œ í™”ì‚´í‘œ ì‹œê°í™” ===
def visualize_path_on_graph(G, pos, labels, path, cluster_id, tour_length, fixed_net_demand):
    import matplotlib.pyplot as plt
    import networkx as nx
    import numpy as np

    unique_labels = np.unique(labels)
    cmap = plt.colormaps.get_cmap("tab10")
    plt.figure(figsize=(10, 7))

    legend_patches = []

    for cid in unique_labels:
        nodes = np.where(labels == cid)[0]
        color = cmap(cid % 10)

        nx.draw_networkx_nodes(
            G, pos,
            nodelist=nodes,
            node_color=[color],
            node_size=600
        )
        legend_patches.append(mpatches.Patch(color=color, label=f"Cluster {cid}"))

        # ğŸ“Œ ë…¸ë“œ ìœ„ì— ìˆ˜ìš” ë²¡í„° í‘œì‹œ (í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ë§Œ)
        if cid == cluster_id:
            for node in nodes:
                demand = fixed_net_demand[node].tolist()
                demand_text = str(demand)
                plt.text(pos[node][0], pos[node][1] + 0.07, demand_text,
                         fontsize=8, ha='center', va='bottom', color='black')

    # í˜„ì¬ í´ëŸ¬ìŠ¤í„°ì˜ ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚°
    nodes = np.where(labels == cluster_id)[0]
    subtotal = fixed_net_demand[nodes].sum(axis=0)
    imbalance = np.abs(subtotal).sum()

    # ê¸°ë³¸ ì—£ì§€ ë° ë¼ë²¨
    nx.draw_networkx_edges(G, pos, edge_color='gray', width=1.2)
    nx.draw_networkx_labels(G, pos, font_weight='bold')

    # ë¹¨ê°„ ê²½ë¡œ ê°•ì¡°
    edge_list = [(path[i], path[i + 1]) for i in range(len(path) - 1)]
    nx.draw_networkx_edges(
        G, pos,
        edgelist=edge_list,
        edge_color='red',
        width=4.0,
        arrows=True,
        arrowsize=30,
        connectionstyle='arc3,rad=0.15'
    )

    # ì œëª©ì— ê±°ë¦¬ + ë¶ˆê· í˜• ì ìˆ˜ ì¶œë ¥
    plt.title(f"Cluster {cluster_id} Path (Distance={tour_length:.2f}, Imbalance={imbalance:.2f})")

    # ë²”ë¡€
    plt.legend(handles=legend_patches, fontsize='small', loc='best', frameon=False)
    plt.axis('off')
    plt.tight_layout()
    plt.show()


# === í´ëŸ¬ìŠ¤í„°ë§ ëœ ì „ì²´ ì§€ë„ë¥¼ ì¶œë ¥ ===
def visualize_clusters(G, pos, labels, title):
    import matplotlib.pyplot as plt
    import networkx as nx
    import numpy as np

    unique_labels = np.unique(labels)
    cmap = plt.colormaps.get_cmap("tab10")

    plt.figure(figsize=(8, 6))

    legend_patches = []  # ìˆ˜ë™ ë²”ë¡€ êµ¬ì„±ìš©

    for cluster_id in unique_labels:
        nodes = np.where(labels == cluster_id)[0]
        color = cmap(cluster_id % 10)
        nx.draw_networkx_nodes(
            G, pos, nodelist=nodes,
            node_color=[color], node_size=600
        )
        # ë²”ë¡€ íŒ¨ì¹˜ ì¶”ê°€ (ë§ˆì»¤ í¬ê¸° ìˆ˜ë™ ì§€ì •)
        legend_patches.append(mpatches.Patch(color=color, label=f"Cluster {cluster_id}"))

    nx.draw_networkx_edges(G, pos, edge_color='gray', width=1.2)
    nx.draw_networkx_labels(G, pos, font_weight='bold')

    plt.title(title)
    plt.axis('off')

    # ë²”ë¡€ í¬ê¸° ì¡°ì ˆ (ë§ˆì»¤ ì‘ê²Œ ì„¤ì •ë¨)
    plt.legend(handles=legend_patches, fontsize='small', loc='best', frameon=False)

    plt.tight_layout()
    plt.show()

# ------------------------------------------------------------------------------------------------
# ------------------------------------- í´ëŸ¬ìŠ¤í„°ë§ ì½”ë“œ --------------------------------------------
# ------------------------------------------------------------------------------------------------

# íŒŒë¼ë¯¸í„° ì§€ì •
'''
ëª©ì í•¨ìˆ˜ = ì”ì—¬ ë¬¼ëŸ‰ + lambda_dist * ê±°ë¦¬ + penalty(í´ëŸ¬ìŠ¤í„° ë‚´ ë…¸ë“œ ê°œìˆ˜ê°€ 2ê°œ ì´í•˜ì¼ ë•Œ ë¶€ì—¬)
ì´ ëª©ì í•¨ìˆ˜ê°€ ìµœì†Œê°€ ë˜ê²Œ í•˜ë„ë¡ ì‘ë™
lambda_dist = 1 : ì”ì—¬ ë¬¼ëŸ‰ê³¼ ê±°ë¦¬ë¥¼ ë˜‘ê°™ì´ ê³ ë ¤
lambda_dist < 1 : ì”ì—¬ ë¬¼ëŸ‰ì„ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤
lambda_dist > 1 : ê±°ë¦¬ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤
'''
# K-Medoids
n_trials = 1000 # K-Medoids í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í—˜ íšŸìˆ˜
threshold = 100 # ê±°ë¦¬ ì œí•œ (ê±°ë¦¬ê°€ 100 ì´ìƒì¸ êµ°ì§‘ì´ ìƒì„±ë˜ì§€ ì•Šë„ë¡ í•¨í•¨)

# ìµœì í™”
lambda_dist = 0.5 # ëª©ì í•¨ìˆ˜ ì¤‘ ê±°ë¦¬ ê°ì†Œ ì¤‘ìš”ë„ ë¹„ìœ¨ ì§€ì • 
n_clusters = 3 # êµ°ì§‘ ìˆ˜ (ê°€ìš© ì°¨ëŸ‰ ëŒ“ìˆ˜ë¡œ ì¹˜í™˜ ê°€ëŠ¥)
max_iter = 300000 # êµ°ì§‘ ì¡°í•© íƒìƒ‰ íšŸìˆ˜
edges_added = 0 # ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œ ìˆ˜
num_link = 30 # ì—°ê²°í•  ë§í¬(ë„ë¡œ) ê°¯ìˆ˜ ì§€ì •


# === ë°ì´í„° ì¤€ë¹„ ===
# ê° ë…¸ë“œë³„ ìˆ˜ìš”, ê³µê¸‰ í–‰ë ¬ (í–‰ = ë…¸ë“œ(ë§ˆì„) / ì—´ = í’ˆëª©)
fixed_net_demand = torch.tensor([
    [ 0,   0,  0], [-3,  -2,  2], [-2,   4,  0], [ 2,  -3,  2], [ 4,  -2, -2],
    [ 0,   1, -1], [-1,   2, -1], [ 1,  -1,  0], [-2,   0,  1], [ 2,   2, -3]
    # [ 0,   0,  1], [-1,   1, -1], [ 1,   1,  1], [ 0,  -2,  2], [-2,  -1,  1],
    # [ 2,  -2,  0], [-1,   2,  1], [ 3,  -1, -1], [ 0,   1, -2], [-1,   0,  2], [ 1,  -1, -1]
], dtype=torch.int32)

size = fixed_net_demand.shape[0]
rng = np.random.default_rng(seed=42)
dist_matrix = np.full((size, size), np.inf)
np.fill_diagonal(dist_matrix, 0.0)


'''
ë„ë¡œ ë°ì´í„°ë¥¼ ì„ì˜ë¡œ ìƒì„±
ì‹¤ì œ ë„ë¡œ ë°ì´í„°ë¥¼ êµ¬í•˜ë©´ ì´ ì½”ë“œëŠ” ì‚­ì œí•˜ê³  ìœ„ì˜ fixed_net_demandì²˜ëŸ¼ ì§ì ‘ ì…ë ¥
'''
while edges_added < num_link:
    i, j = rng.integers(0, size, size=2)
    if i != j and dist_matrix[i][j] == np.inf:
        dist = rng.uniform(1.0, 3.0) # 1~3 ì¤‘ unifrom distë¡œ í•˜ë‚˜ ì„ íƒ
        dist_matrix[i][j] = dist_matrix[j][i] = dist
        edges_added += 1

# ê·¸ë˜í”„ êµ¬ì„±
G = nx.Graph()
for i in range(size):
    for j in range(i + 1, size):
        if np.isfinite(dist_matrix[i][j]) and dist_matrix[i][j] > 0:
            G.add_edge(i, j, weight=1 / dist_matrix[i][j])
            
pos = nx.spring_layout(G, seed=42, weight='weight')

# ê±°ë¦¬ â†’ ìœ ì‚¬ë„ â†’ ê±°ë¦¬
tf_dist_matrix = np.where(np.isinf(dist_matrix), 100.0, dist_matrix)
dist_sim = np.exp(-tf_dist_matrix)
combined_dist = 1 - dist_sim
np.fill_diagonal(combined_dist, 0.0)


# í´ëŸ¬ìŠ¤í„°ë§
# best = KMedoids ê²°ê³¼
results = evaluate_clustering(fixed_net_demand.numpy(), dist_matrix=combined_dist, 
                              n_clusters=n_clusters, trials=n_trials, threshold=threshold)
best = results[0]
labels = best['labels']

import numpy as np
import copy
import random

init_labels = best['labels']
optimized_labels, optimized_score = simulated_annealing(
    fixed_net_demand.numpy(),
    init_labels,
    tf_dist_matrix, 
    lambda_dist=lambda_dist,
    n_clusters=n_clusters,
    max_iter=max_iter
)

# ê° í´ëŸ¬ìŠ¤í„°ë³„ ê²°ê³¼ ì¶œë ¥ & ì‹œê°í™”
visualize_clusters(G, pos, optimized_labels, title="Metaheuristic Optimization Result")
print_cluster_details_and_paths(fixed_net_demand.numpy(), optimized_labels, tf_dist_matrix, G, pos)

# ì´ ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚°
imbalance_score = supply_demand_imbalance_score(fixed_net_demand.numpy(), optimized_labels)

print("\nâœ… ëª©ì í•¨ìˆ˜ ì ìˆ˜:", optimized_score)
print(f"ğŸ“Š ë¶ˆê· í˜• ì ìˆ˜ ì´í•©: {imbalance_score}")
