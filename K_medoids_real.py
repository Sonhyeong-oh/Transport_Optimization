'''
ìˆ˜ì •í•´ì•¼ í•  ì‚¬í•­
1. ì‹¤ì œ ë°ì´í„°ë¡œ ëŒë ¤ë³´ê¸°
2. multiple_run_sa í•¨ìˆ˜ì˜ ìµœì  n_runs ì°¾ê¸°
'''

import numpy as np
import torch
import matplotlib.pyplot as plt
import networkx as nx
from sklearn_extra.cluster import KMedoids
from sklearn.metrics import silhouette_score
import matplotlib.patches as mpatches
import warnings
import random
import Clustering_function as cf
warnings.filterwarnings("ignore", category=DeprecationWarning)

'''
*** ìš©ì–´ ì„¤ëª… ***

ì”ì—¬ ë¬¼ëŸ‰ = í•´ë‹¹ êµ°ì§‘ìœ¼ë¡œ ë°°ì†¡ ì§„í–‰ ì‹œ ì´ˆê³¼ëœ or ë¶€ì¡±í•œ ë¬¼ëŸ‰
ë¶ˆê· í˜• ì ìˆ˜ = ì”ì—¬ ë¬¼ëŸ‰ì˜ ë¬¼í’ˆ ë³„(ì—´ ë³„) ì ˆëŒ“ê°’ì„ ëª¨ë‘ ë”í•œ ê°’

ex) êµ°ì§‘ ê²½ë¡œë¡œ ëª¨ë‘ ë°°ì†¡í•œ í›„ì˜ ì‚¬ê³¼, ë°°, ë°”ë‚˜ë‚˜ = [2, -1, 0] : ì”ì—¬ ë¬¼ëŸ‰
ì‚¬ê³¼ëŠ” 2ë§Œí¼ ë‚¨ìŒ(ê³µê¸‰ ê³¼ì‰), ë°°ëŠ” 1ê°œ ë¶€ì¡±í•¨(ê³µê¸‰ ë¶€ì¡±), ë°”ë‚˜ë‚˜ëŠ” ìˆ˜ìš”ì™€ ê³µê¸‰ì´ ì¼ì¹˜í–ˆìŒ
ë¶ˆê· í˜• ì ìˆ˜ = |2| + |-1| + |0| = 3

ë°©ë¬¸ ê²½ë¡œ = ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°°ì†¡ ì§„í–‰
'''

# ------------------------------------------------------------------------------------------------
# ------------------------------------- í´ëŸ¬ìŠ¤í„°ë§ ì½”ë“œ --------------------------------------------
# ------------------------------------------------------------------------------------------------

# íŒŒë¼ë¯¸í„° ì§€ì •
'''
ëª©ì í•¨ìˆ˜ = ì”ì—¬ ë¬¼ëŸ‰ + lambda_dist * ê±°ë¦¬ + penalty(í´ëŸ¬ìŠ¤í„° ë‚´ ë…¸ë“œ ê°œìˆ˜ê°€ 2ê°œ ì´í•˜ì¼ ë•Œ ë¶€ì—¬)
ì´ ëª©ì í•¨ìˆ˜ê°€ ìµœì†Œê°€ ë˜ê²Œ í•˜ë„ë¡ ì‘ë™
lambda_dist = 1 : ì”ì—¬ ë¬¼ëŸ‰ê³¼ ê±°ë¦¬ë¥¼ ë˜‘ê°™ì´ ê³ ë ¤
lambda_dist < 1 : ì”ì—¬ ë¬¼ëŸ‰ì„ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤
lambda_dist > 1 : ê±°ë¦¬ë¥¼ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤
'''
# K-Medoids
n_trials = 1000 # K-Medoids í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í—˜ íšŸìˆ˜
threshold = 100 # ê±°ë¦¬ ì œí•œ (ê±°ë¦¬ê°€ 100 ì´ìƒì¸ êµ°ì§‘ì´ ìƒì„±ë˜ì§€ ì•Šë„ë¡ í•¨í•¨)

# ìµœì í™”
lambda_dist = 0.3 # ëª©ì í•¨ìˆ˜ ì¤‘ ê±°ë¦¬ ê°ì†Œ ì¤‘ìš”ë„ ë¹„ìœ¨ ì§€ì • 
n_clusters = 5 # êµ°ì§‘ ìˆ˜ (ê°€ìš© ì°¨ëŸ‰ ëŒ“ìˆ˜ë¡œ ì¹˜í™˜ ê°€ëŠ¥)
max_iter = 100000 # êµ°ì§‘ ì¡°í•© íƒìƒ‰ íšŸìˆ˜
n_runs = 3 # ìµœì í™” ì‹œí–‰ íšŸìˆ˜


# === ë°ì´í„° ì¤€ë¹„ ===
# ê° ë…¸ë“œë³„ ìˆ˜ìš”, ê³µê¸‰ í–‰ë ¬ (í–‰ = ë…¸ë“œ(ë§ˆì„) / ì—´ = í’ˆëª©)
fixed_net_demand = cf.generate_fixed_net_demand(n_nodes=18)
print(fixed_net_demand)
size = fixed_net_demand.shape[0]
rng = np.random.default_rng(seed=42)


# ì‹œ(êµ°)ì²­ ë³„ ê±°ë¦¬ ë°ì´í„°
dist_matrix = torch.tensor([
    #ì¶˜ì²œ ì›ì£¼  ê°•ë¦‰  ë™í•´  íƒœë°± ì†ì´ˆ  ì‚¼ì²™  í™ì²œ íš¡ì„±  ì˜ì›”  í‰ì°½ ì •ì„   ì² ì›  í™”ì²œ ì–‘êµ¬  ì¸ì œ  ê³ ì„±  ì–‘ì–‘
    [0,   84,  160, 200, 222, 108, 209, 38,  61,  150, 119, 148, 78,  30,  44,  82,  116, 114], # ì¶˜ì²œ
    [84,  0,   127, 166, 141, 181, 175, 60,  20,  72,  70,  123, 156, 112, 122, 112, 202, 158], # ì›ì£¼
    [160, 127, 0,   47,  99,  65,  59,  134, 107, 117, 90,  68,  243, 187, 128, 110, 96,  53 ], # ê°•ë¦‰
    [200, 166, 47,  0,   54,  104, 14,  173, 146, 114, 129, 76,  282, 227, 168, 150, 136, 89 ], # ë™í•´
    [222, 141, 99,  54,  0,   164, 47,  189, 159, 64,  84,  52,  287, 249, 216, 198, 185, 142], # íƒœë°±
    [108, 181, 65,  104, 164, 0,   118, 105, 138, 171, 144, 138, 221, 118, 67,  50,  25,  17 ], # ì†ì´ˆ
    [209, 175, 59,  14,  47,  118, 0,   184, 159, 108, 107, 78,  293, 237, 178, 160, 147, 102], # ì‚¼ì²™
    [38,  60,  134, 173, 189, 105, 184, 0,   34,  124, 87,  116, 123, 65,  64,  54,  109, 90 ], # í™ì²œ
    [61,  20,  107, 146, 159, 138, 159, 34,  0,   95,  55,  85,  145, 87,  97,  83,  178, 119], # íš¡ì„±
    [150, 72,  117, 114, 64,  171, 108, 124, 95,  0,   29,  52,  224, 187, 197, 186, 199, 151], # ì˜ì›”
    [119, 70,  90,  129, 84,  144, 107, 87,  55,  29,  0,   31,  211, 143, 150, 128, 171, 124], # í‰ì°½
    [148, 123, 68,  76,  52,  138, 78,  116, 85,  52,  31,  0,   262, 220, 197, 142, 166, 118], # ì •ì„ 
    [78,  156, 243, 282, 287, 221, 293, 123, 145, 224, 211, 262, 0,   61,  119, 149, 192, 211], # ì² ì›
    [30,  112, 187, 227, 249, 118, 237, 65,  87,  187, 143, 220, 61,  0,   44,  73,  155, 143], # í™”ì²œ
    [44,  122, 128, 168, 216, 67,  178, 64,  97,  197, 150, 197, 119, 44,  0,   31,  75,  74 ], # ì–‘êµ¬
    [82,  112, 110, 150, 198, 50,  160, 54,  83,  186, 128, 142, 149, 73,  31,  0,   57,  55 ], # ì¸ì œ
    [116, 202, 96,  136, 185, 25,  147, 109, 178, 199, 171, 166, 192, 155, 75,  57,  0,   43 ], # ê³ ì„±
    [114, 158, 53,  89,  142, 17,  102, 90,  119, 151, 124, 118, 211, 143, 74,  55,  43,  0  ]  # ì–‘ì–‘
])


# ê·¸ë˜í”„ êµ¬ì„±
G = nx.Graph()
for i in range(size):
    for j in range(i + 1, size):
        if np.isfinite(dist_matrix[i][j]) and dist_matrix[i][j] > 0:
            G.add_edge(i, j, weight=1 / dist_matrix[i][j])
            
pos = nx.spring_layout(G, seed=42, weight='weight')

# ê±°ë¦¬ â†’ ìœ ì‚¬ë„ â†’ ê±°ë¦¬
dist_sim = torch.exp(-dist_matrix)
combined_dist = 1 - dist_sim
combined_dist.fill_diagonal_(0.0)


# í´ëŸ¬ìŠ¤í„°ë§
# best = KMedoids ê²°ê³¼
results = cf.evaluate_clustering(fixed_net_demand.numpy(), dist_matrix=combined_dist, 
                              n_clusters=n_clusters, trials=n_trials, threshold=threshold)
best = results[0]
labels = best['labels']

cf.visualize_clusters(G, pos, labels, title="K-Medoids Result")
cf.print_cluster_details_and_paths(fixed_net_demand.numpy(), labels, dist_matrix, G, pos)

init_labels = best['labels']
best_labels, best_score = cf.multiple_runs_sa(
    fixed_net_demand, init_labels, dist_matrix,
    n_clusters=n_clusters, lambda_dist=lambda_dist, 
    max_iter = max_iter, n_runs = n_runs
)

# ê° í´ëŸ¬ìŠ¤í„°ë³„ ê²°ê³¼ ì¶œë ¥ & ì‹œê°í™”
cf.visualize_clusters(G, pos, best_labels, title="Metaheuristic Optimization Result")
cf.print_cluster_details_and_paths(fixed_net_demand.numpy(), best_labels, dist_matrix, G, pos)

# ì´ ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚°
imbalance_score = cf.supply_demand_imbalance_score(fixed_net_demand.numpy(), best_labels)

print("\nâœ… ëª©ì í•¨ìˆ˜ ì ìˆ˜:", best_score)
print(f"ğŸ“Š ë¶ˆê· í˜• ì ìˆ˜ ì´í•©: {imbalance_score}")
